<PlatformWrapper platform="react-native">

This article describes how to build a React Native project that implements the voice call function using the Agora React Native SDK.

## Understand the tech

$$0bc9e410-d000-11eb-9521-2d3265d0c546
{
"platform":"framework"
}
$$

~e71cdb40-edab-11ea-b8b9-41d66d687758~

## Implementation

### 1. Create the UI

Create the user interface (UI) for the audio call in the layout file of your project. 

For a audio call, we recommend adding the following elements into the UI:

- The join/leave button
- The  mute/unmute button

The `components/Style.ts` file in the [Agora-RN-Quickstart](https://github.com/AgoraIO-Community/Agora-RN-Quickstart) sample project defines the styles of the UI elements. You can create a `components` folder for your project, add a `Style.ts` file under that folder, and then copy the following code to the file:

```typescript
import {StyleSheet} from 'react-native'
 
 
export default StyleSheet.create({
  container: {
    flex: 1,
  },
  float: {
    position: 'absolute',
    right: 0,
    bottom: 0,
  },
  top: {
    width: '100%',
  },
  input: {
    borderColor: 'gray',
    borderWidth: 1,
  },
})
```

### 2. Import classes

Open the `App.tsx` file, and delete all code. Add the following code to the beginning of the `App.tsx` file:

```typescript
import React, {Component} from 'react'
import {Platform, Button, TextInput, View, PermissionsAndroid} from 'react-native'
// Import the RtcEngine class into your project.
import RtcEngine from 'react-native-agora'
// Import the UI styles.
import styles from './components/Style'
```

### 3. Add project permissions

~0a2693f0-d709-11eb-b768-51ffcd29c763~

### 4. Create an App component

~7b2fd800-50f7-11ec-8689-2164ade84c59~

```typescript
// Define a Props interface.
interface Props {
}
 
// Define a State interface.
interface State {
    appId: string,
    token: string,
    channelName: string,
    joinSucceed: boolean,
    openMicrophone: boolean,
    enableSpeakerphone: boolean,
    peerIds: number[],
}
 
// Create an App component, which extends the properties of the Pros and State interfaces.
export default class App extends Component<Props, State> {
    _engine?: RtcEngine
    // Add a constructor，and initialize this.state. You need:
    // Replace yourAppId with the App ID of your Agora project.
    // Replace yourChannel with the channel name that you want to join.
    // Replace yourToken with the token that you generated using the App ID and channel name above.
    constructor(props) {
        super(props)
        this.state = {
            appId: `yourAppId`,
            token: 'yourToken',
            channelName: 'yourChannel',
            openMicrophone: true,
            enableSpeakerphone: true,
            joinSucceed: false,
            peerIds: [],
        }
        if (Platform.OS === 'android') {
            // Request required permissions from Android
            requestCameraAndAudioPermission().then(() => {
                console.log('requested!')
            })
        }
    }
    // Other code. See step 5 to step 9.
    ...
}
```

### 5. Initialize RtcEngine

Create and initialize the `RtcEngine` object before calling any other Agora APIs.

You can also listen for callback events, such as when the local user joins the channel, when a remote user joins the channel, and when a remote user leaves the channel.

Add the following code after `// Other code` in `App.tsx`：

```typescript
// Mount the App component into the DOM.
componentDidMount() {
    this.init()
}
// Pass in your App ID through this.state, create and initialize an RtcEngine object.
init = async () => {
    const {appId} = this.state
    this._engine = await RtcEngine.create(appId)
    // Enable the audio module.
    await this._engine.enableAudio()

 
    // Listen for the UserJoined callback.
    // This callback occurs when the remote user successfully joins the channel.
    this._engine.addListener('UserJoined', (uid, elapsed) => {
        console.log('UserJoined', uid, elapsed)
        const {peerIds} = this.state
        if (peerIds.indexOf(uid) === -1) {
            this.setState({
                peerIds: [...peerIds, uid]
            })
        }
    })
 
 
    // Listen for the UserOffline callback.
    // This callback occurs when the remote user leaves the channel or drops offline.
    this._engine.addListener('UserOffline', (uid, reason) => {
        console.log('UserOffline', uid, reason)
        const {peerIds} = this.state
        this.setState({
            // Remove peer ID from state array
            peerIds: peerIds.filter(id => id !== uid)
        })
    })
     
    // Listen for the JoinChannelSuccess callback.
    // This callback occurs when the local user successfully joins the channel.
    this._engine.addListener('JoinChannelSuccess', (channel, uid, elapsed) => {
        console.log('JoinChannelSuccess', channel, uid, elapsed)
        this.setState({
            joinSucceed: true
        })
    })
}
```

### 6.  Join a channel

After initializing the `RtcEngine` object, you can call `joinChannel` to join a channel. 

```typescript
// Pass in your token and channel name through this.state.token and this.state.channelName.
// Set the ID of the local user, which is an integer and should be unique. If you set uid as 0,
// the SDK assigns a user ID for the local user and returns it in the JoinChannelSuccess callback.
_joinChannel = async () => {
        await this._engine?.joinChannel(this.state.token, this.state.channelName, null, 0)
    }
```

### 7. Switch audio devices

During a voice call, the user can click the button on the user interface to turn the microphone on or off, or switch the audio playback device.

```typescript
// Turn the microphone on or off.
_switchMicrophone = () => {
        const { openMicrophone } = this.state
        this._engine?.enableLocalAudio(!openMicrophone).then(() => {
            this.setState({ openMicrophone: !openMicrophone })
          }).catch((err) => {
            console.warn('enableLocalAudio', err)
          })
      }
 
// Switch the audio playback device.
_switchSpeakerphone = () => {
        const { enableSpeakerphone } = this.state
        this._engine?.setEnableSpeakerphone(!enableSpeakerphone).then(() => {
            this.setState({ enableSpeakerphone: !enableSpeakerphone })
          }).catch((err) => {
            console.warn('setEnableSpeakerphone', err)
          })
      }
```

### 8. Render UI elements

Call the `render()` method in the App component to render the UI elements and handle the button click event.

```typescript
render() {
        const {
            channelName,
            joinSucceed,
            openMicrophone,
            enableSpeakerphone,
          } = this.state;
        return (
            <View style={styles.container}>
              <View style={styles.top}>
                <TextInput
                  style={styles.input}
                  onChangeText={(text) => this.setState({ channelName: text })}
                  placeholder={'Channel Name'}
                  value={channelName}
                />
                <Button
                  onPress={joinSucceed ? this._leaveChannel : this._joinChannel}
                  title={`${joinSucceed ? 'Leave' : 'Join'} channel`}
                />
              </View>
              <View style={styles.float}>
                <Button
                  onPress={this._switchMicrophone}
                  title={`Microphone ${openMicrophone ? 'on' : 'off'}`}
                />
                <Button
                  onPress={this._switchSpeakerphone}
                  title={enableSpeakerphone ? 'Speakerphone' : 'Earpiece'}
                />
              </View>
            </View>
        )
 }
```

### 9. Leave the channel

Call `leaveChannel` to leave the current channel according to your scenario. For example, when the audio call ends, when you need to close the app, or when your app runs in the background.

```typescript
_leaveChannel = async () => {
        await this._engine?.leaveChannel()
        this.setState({peerIds: [], joinSucceed: false})
    }
```

## Run the project

Agora recommends you run this project on a physical mobile device, as some simulators may not support the full features of this project.

**To run the Android app on a physical device:**

1. Enable the **Developer options** on your Android device, and then connect it to your computer using a USB cable.
2. Run `npx react-native run-android` in the project root directory. 

**To run the iOS app on a physical device:**

1. Open the `ProjectName/ios/ProjectName.xcworkspace` folder with Xcode.
2. Connect your iOS device to your computer using a USB cable.
3. Click the **Build and run** button in Xcode.

You should see the app installed on your device after a while. You can hear the remote users when you successfully start a voice call in the app.

</PlatformWrapper>